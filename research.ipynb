{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "The main goal of the project to create a Data Lake in S3 using Airflow trigger Spark.  \n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import configparser\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as func\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"DataEngineeringCapstoneProject\").getOrCreate()\n",
    "\n",
    "# spark = SparkSession.builder.\\\n",
    "# config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    "# .enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "The scope of project is to build a Data Mode to analysis CVID-19 world vaccination progress. For example We can analysis where need to speed up vaccination progress.\n",
    "\n",
    "#### The following technologies were used: \n",
    "- Spark\n",
    "- Airflow\n",
    "- AWS EMR S3 \n",
    "\n",
    "#### Describe and Gather Data \n",
    "\n",
    "##### 1.The Data sources:\n",
    "\n",
    "The Daily and Total Vaccination for COVID-19 in the world is provided by Kaggle\n",
    "- [country_vaccinations.csv](https://www.kaggle.com/gpreda/covid-world-vaccination-progress)\n",
    "\n",
    "WHO Coronavirus Disease (COVID-19) is provided by WHO\n",
    "- [WHO-COVID-19-global-data.csv](https://covid19.who.int/)\n",
    "\n",
    "ISO country code provide by Kaggle\n",
    "- [country_code.csv](https://www.kaggle.com/koki25ando/country-code)\n",
    "\n",
    "The Data contains 12 columns provide by Kaggle\n",
    " - [ Countries_usefulFeatures.csv](https://www.kaggle.com/ishivinal/covid19-useful-features-by-country)\n",
    " \n",
    "The Data extracted from Wikipedia's list of countries by category is provided by Kaggle \n",
    " - [WORLD DATA by country (2020)](https://www.kaggle.com/daniboy370/world-data-by-country-2020?select=Life+expectancy.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.Gather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set('spark.sql.session.timeZone', 'UTC') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVID19_vaccinations_spark = spark.read.csv(\"data/country_vaccinations.csv\",sep=\",\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The data contains the following information:\n",
    "\n",
    " - Country- this is the country for which the vaccination information is provided;\n",
    " - Country ISO Code - ISO code for the country;\n",
    " - Date - date for the data entry; for some of the dates we have only the daily vaccinations, for others, only the (cumulative) total;\n",
    " - Total number of vaccinations - this is the absolute number of total immunizations in the country;\n",
    " - Total number of people vaccinated - a person, depending on the immunization scheme, will receive one or more (typically 2) vaccines; at a certain moment, the number of vaccination might be larger than the number of people;\n",
    " - Total number of people fully vaccinated - this is the number of people that received the entire set of immunization according to the immunization scheme (typically 2); at a certain moment in time, there might be a certain number of people that received one vaccine and another number (smaller) of people that received all vaccines in the scheme;\n",
    " - Daily vaccinations (raw) - for a certain data entry, the number of vaccination for that date/country;\n",
    " - Daily vaccinations - for a certain data entry, the number of vaccination for that date/country;\n",
    " - Total vaccinations per hundred - ratio (in percent) between vaccination number and total population up to the date in the country;\n",
    " - Total number of people vaccinated per hundred - ratio (in percent) between population immunized and total population up to the date in the country;\n",
    " - Total number of people fully vaccinated per hundred - ratio (in percent) between population fully immunized and total population up to the date in the country;\n",
    " - Number of vaccinations per day - number of daily vaccination for that day and country;\n",
    " - Daily vaccinations per million - ratio (in ppm) between vaccination number and total population for the current date in the country;\n",
    " - Vaccines used in the country - total number of vaccines used in the country (up to date);\n",
    " - Source name - source of the information (national authority, international organization, local organization etc.);\n",
    " - Source website - website of the source of information;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country: string (nullable = true)\n",
      " |-- iso_code: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- total_vaccinations: double (nullable = true)\n",
      " |-- people_vaccinated: double (nullable = true)\n",
      " |-- people_fully_vaccinated: double (nullable = true)\n",
      " |-- daily_vaccinations_raw: double (nullable = true)\n",
      " |-- daily_vaccinations: double (nullable = true)\n",
      " |-- total_vaccinations_per_hundred: double (nullable = true)\n",
      " |-- people_vaccinated_per_hundred: double (nullable = true)\n",
      " |-- people_fully_vaccinated_per_hundred: double (nullable = true)\n",
      " |-- daily_vaccinations_per_million: double (nullable = true)\n",
      " |-- vaccines: string (nullable = true)\n",
      " |-- source_name: string (nullable = true)\n",
      " |-- source_website: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "COVID19_vaccinations_spark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add columns *year*  *month*  *week*  for aggregating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COVID19_vaccinations_spark = COVID19_vaccinations_spark.withColumn('year', func.year('date'))\\\n",
    "#                               .withColumn('month', func.month('date'))\\\n",
    "#                               .withColumn('week_of_year', func.weekofyear('date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+----------+------------------+-----------------+-----------------------+----------------------+------------------+------------------------------+-----------------------------+-----------------------------------+------------------------------+---------------+------------------+--------------------+\n",
      "|country|iso_code|      date|total_vaccinations|people_vaccinated|people_fully_vaccinated|daily_vaccinations_raw|daily_vaccinations|total_vaccinations_per_hundred|people_vaccinated_per_hundred|people_fully_vaccinated_per_hundred|daily_vaccinations_per_million|       vaccines|       source_name|      source_website|\n",
      "+-------+--------+----------+------------------+-----------------+-----------------------+----------------------+------------------+------------------------------+-----------------------------+-----------------------------------+------------------------------+---------------+------------------+--------------------+\n",
      "|Albania|     ALB|2021-01-10|               0.0|              0.0|                   null|                  null|              null|                           0.0|                          0.0|                               null|                          null|Pfizer/BioNTech|Ministry of Health|https://shendetes...|\n",
      "+-------+--------+----------+------------------+-----------------+-----------------------+----------------------+------------------+------------------------------+-----------------------------+-----------------------------------+------------------------------+---------------+------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "COVID19_vaccinations_spark.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVID19_global_spark = spark.read.csv(\"data/WHO-COVID-19-global-data.csv\",sep=\",\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date_reported: string (nullable = true)\n",
      " |-- Country_code: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- WHO_region: string (nullable = true)\n",
      " |-- New_cases: integer (nullable = true)\n",
      " |-- Cumulative_cases: integer (nullable = true)\n",
      " |-- New_deaths: integer (nullable = true)\n",
      " |-- Cumulative_deaths: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "COVID19_global_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+-----------+----------+---------+----------------+----------+-----------------+\n",
      "|Date_reported|Country_code|    Country|WHO_region|New_cases|Cumulative_cases|New_deaths|Cumulative_deaths|\n",
      "+-------------+------------+-----------+----------+---------+----------------+----------+-----------------+\n",
      "|     2020/1/3|          AF|Afghanistan|      EMRO|        0|               0|         0|                0|\n",
      "|     2020/1/4|          AF|Afghanistan|      EMRO|        0|               0|         0|                0|\n",
      "|     2020/1/5|          AF|Afghanistan|      EMRO|        0|               0|         0|                0|\n",
      "|     2020/1/6|          AF|Afghanistan|      EMRO|        0|               0|         0|                0|\n",
      "|     2020/1/7|          AF|Afghanistan|      EMRO|        0|               0|         0|                0|\n",
      "+-------------+------------+-----------+----------+---------+----------------+----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "COVID19_global_spark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_code_spark = spark.read.csv(\"data/country_code.csv\",sep=\",\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- Country_name: string (nullable = true)\n",
      " |-- code_2digit: string (nullable = true)\n",
      " |-- code_3digit: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country_code_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+-----------+-----------+\n",
      "|_c0|  Country_name|code_2digit|code_3digit|\n",
      "+---+--------------+-----------+-----------+\n",
      "|  2|   Afghanistan|         AF|        AFG|\n",
      "|  3| Aland Islands|         AX|        ALA|\n",
      "|  4|       Albania|         AL|        ALB|\n",
      "|  5|       Algeria|         DZ|        DZA|\n",
      "|  6|American Samoa|         AS|        ASM|\n",
      "+---+--------------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country_code_spark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVID19_usefulFeatures_spark = spark.read.csv(\"data/Countries_usefulFeatures.csv\",sep=\",\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Country_Region: Name of the country\n",
    "- Population_Size: the population size 2018 stats\n",
    "- Tourism: International tourism, number of arrivals 2018\n",
    "- Date_FirstFatality: Date of the first Fatality of the COVID-19\n",
    "- Date_FirstConfirmedCase: Date of the first confirmed case of the COVID-19\n",
    "- Latitude\n",
    "- Longitude\n",
    "- Mean_Age: mean age of the population 2018 stats\n",
    "- Lockdown_Date: date of the lockdown\n",
    "- Lockdown_Type: type of the lockdown\n",
    "- Country_Code: 3 digit country code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country_Region: string (nullable = true)\n",
      " |-- Population_Size: integer (nullable = true)\n",
      " |-- Tourism: integer (nullable = true)\n",
      " |-- Date_FirstFatality: string (nullable = true)\n",
      " |-- Date_FirstConfirmedCase: string (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longtitude: double (nullable = true)\n",
      " |-- Mean_Age: double (nullable = true)\n",
      " |-- Lockdown_Date: string (nullable = true)\n",
      " |-- Lockdown_Type: string (nullable = true)\n",
      " |-- Country_Code: string (nullable = true)\n",
      "\n",
      "+--------------+---------------+-------+------------------+-----------------------+----------+------------------+--------+-------------+-------------+------------+\n",
      "|Country_Region|Population_Size|Tourism|Date_FirstFatality|Date_FirstConfirmedCase|  Latitude|        Longtitude|Mean_Age|Lockdown_Date|Lockdown_Type|Country_Code|\n",
      "+--------------+---------------+-------+------------------+-----------------------+----------+------------------+--------+-------------+-------------+------------+\n",
      "|   Afghanistan|       37172386|  14000|        2020-03-23|             2020-02-25|  33.93911|         67.709953|    17.3|   2020-03-24|         Full|         AFG|\n",
      "|       Albania|        2866376|5340000|        2020-03-12|             2020-03-10| 41.153332|         20.168331|    36.2|   2020-03-08|         Full|         ALB|\n",
      "|       Algeria|       42228429|2657000|        2020-03-13|             2020-02-26| 28.033886|1.6596259999999998|    27.5|   2020-03-24|         Full|         DZA|\n",
      "|       Andorra|          77006|3042000|        2020-03-23|             2020-03-03| 42.546245|          1.601554|    37.0|   2020-03-16|         Full|         AND|\n",
      "|        Angola|       30809762| 218000|        2020-03-30|             2020-03-21|-11.202692|         17.873887|    16.4|         null|         null|         AGO|\n",
      "+--------------+---------------+-------+------------------+-----------------------+----------+------------------+--------+-------------+-------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "COVID19_usefulFeatures_spark.printSchema()\n",
    "COVID19_usefulFeatures_spark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_GDP_spark = spark.read.csv(\"data/WORLD DATA by country (2020)/GDP per capita.csv\",sep=\",\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country: string (nullable = true)\n",
      " |-- GDP per capita: double (nullable = true)\n",
      " |-- ISO-code: string (nullable = true)\n",
      "\n",
      "+-------------------+--------------+--------+\n",
      "|            Country|GDP per capita|ISO-code|\n",
      "+-------------------+--------------+--------+\n",
      "|        Afghanistan|        2182.0|     AFG|\n",
      "|            Albania|       14866.0|     ALB|\n",
      "|            Algeria|       16091.0|     DZA|\n",
      "|             Angola|        6763.0|     AGO|\n",
      "|Antigua and Barbuda|       30593.0|     ATG|\n",
      "+-------------------+--------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country_GDP_spark.printSchema()\n",
    "country_GDP_spark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_life_expectancy_spark = spark.read.csv(\"data/WORLD DATA by country (2020)/Life expectancy.csv\",sep=\",\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Life expectancy: double (nullable = true)\n",
      " |-- ISO-code: string (nullable = true)\n",
      "\n",
      "+-------------------+---------------+--------+\n",
      "|            Country|Life expectancy|ISO-code|\n",
      "+-------------------+---------------+--------+\n",
      "|        Afghanistan|           64.5|     AFG|\n",
      "|            Algeria|           76.7|     DZA|\n",
      "|            Andorra|           81.8|     AND|\n",
      "|             Angola|           60.8|     AGO|\n",
      "|Antigua and Barbuda|           76.9|     ATG|\n",
      "+-------------------+---------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country_life_expectancy_spark.printSchema()\n",
    "country_life_expectancy_spark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Median age: double (nullable = true)\n",
      " |-- ISO-code: string (nullable = true)\n",
      "\n",
      "+--------------+----------+--------+\n",
      "|       Country|Median age|ISO-code|\n",
      "+--------------+----------+--------+\n",
      "|   Afghanistan|      27.4|     AFG|\n",
      "|       Albania|      32.9|     ALB|\n",
      "|       Algeria|      28.1|     DZA|\n",
      "|American Samoa|      25.5|     ASM|\n",
      "|       Andorra|      44.3|     AND|\n",
      "+--------------+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country_median_age_spark = spark.read.csv(\"data/WORLD DATA by country (2020)/Median age.csv\",sep=\",\", inferSchema=True, header=True)\n",
    "country_median_age_spark.printSchema()\n",
    "country_median_age_spark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Population growth: double (nullable = true)\n",
      " |-- ISO-code: string (nullable = true)\n",
      "\n",
      "+--------------+-----------------+--------+\n",
      "|       Country|Population growth|ISO-code|\n",
      "+--------------+-----------------+--------+\n",
      "|   Afghanistan|             2.41|     AFG|\n",
      "|       Albania|             0.26|     ALB|\n",
      "|       Algeria|             1.89|     DZA|\n",
      "|American Samoa|            -0.26|     ASM|\n",
      "|       Andorra|             0.63|     AND|\n",
      "+--------------+-----------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country_population_growth_spark = spark.read.csv(\"data/WORLD DATA by country (2020)/Population growth.csv\",sep=\",\", inferSchema=True, header=True)\n",
    "country_population_growth_spark.printSchema()\n",
    "country_population_growth_spark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Urbanization rate: double (nullable = true)\n",
      " |-- ISO-code: string (nullable = true)\n",
      "\n",
      "+---------+-----------------+--------+\n",
      "|  Country|Urbanization rate|ISO-code|\n",
      "+---------+-----------------+--------+\n",
      "|   Monaco|            100.0|     MCO|\n",
      "|    Nauru|            100.0|     NRU|\n",
      "|Singapore|            100.0|     SGP|\n",
      "| Anguilla|            100.0|     AIA|\n",
      "|  Bermuda|            100.0|     BMU|\n",
      "+---------+-----------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country_urbanization_rate_spark = spark.read.csv(\"data/WORLD DATA by country (2020)/Urbanization rate.csv\",sep=\",\", inferSchema=True, header=True)\n",
    "country_urbanization_rate_spark.printSchema()\n",
    "country_urbanization_rate_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Explore and Cleaning  *COVID19_vaccinations_spark DataFrame*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': '0.00%',\n",
       " 'iso_code': '6.85%',\n",
       " 'date': '0.00%',\n",
       " 'total_vaccinations': '34.25%',\n",
       " 'people_vaccinated': '44.01%',\n",
       " 'people_fully_vaccinated': '62.53%',\n",
       " 'daily_vaccinations_raw': '44.37%',\n",
       " 'daily_vaccinations': '3.47%',\n",
       " 'total_vaccinations_per_hundred': '34.25%',\n",
       " 'people_vaccinated_per_hundred': '44.01%',\n",
       " 'people_fully_vaccinated_per_hundred': '62.53%',\n",
       " 'daily_vaccinations_per_million': '3.47%',\n",
       " 'vaccines': '0.00%',\n",
       " 'source_name': '0.00%',\n",
       " 'source_website': '0.00%'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the Null value columns\n",
    "count = COVID19_vaccinations_spark.count()\n",
    "{col: f'{ COVID19_vaccinations_spark.filter(COVID19_vaccinations_spark[col].isNull()).count()/count *100 :.2f}%'\\\n",
    "for col in COVID19_vaccinations_spark.columns}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'iso_code' fill NULL as iso country code. Other column null value are filled with 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|         country|count|\n",
      "+----------------+-----+\n",
      "|           Wales|   76|\n",
      "|         England|   76|\n",
      "|        Scotland|   76|\n",
      "|Northern Ireland|   76|\n",
      "+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dict_null = COVID19_vaccinations_spark.select(\"country\",\"iso_code\")\\\n",
    "                          .filter(COVID19_vaccinations_spark[\"iso_code\"].isNull()).groupBy(\"country\").count()\n",
    "dict_null.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaccinations_cleaned = COVID19_vaccinations_spark.fillna({\"iso_code\":\"GBR\", \"total_vaccinations\":0.0, \"people_vaccinated\":0.0, \"people_fully_vaccinated\":0.0,\\\n",
    "                       \"daily_vaccinations_raw\":0.0, \"daily_vaccinations\":0.0, \"total_vaccinations_per_hundred\":0.0,\\\n",
    "                                    \"people_vaccinated_per_hundred\":0.0, \"people_fully_vaccinated_per_hundred\":0.0,\\\n",
    "                                    \"daily_vaccinations_per_million\":0.0\n",
    "                                   })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Explore and Cleaning *COVID19_global_spark* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date_reported': '0.00%',\n",
       " 'Country_code': '0.00%',\n",
       " 'Country': '0.00%',\n",
       " 'WHO_region': '0.00%',\n",
       " 'New_cases': '0.00%',\n",
       " 'Cumulative_cases': '0.00%',\n",
       " 'New_deaths': '0.00%',\n",
       " 'Cumulative_deaths': '0.00%'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the Null value columns\n",
    "count = COVID19_global_spark.count()\n",
    "{col: f'{ COVID19_global_spark.filter(COVID19_global_spark[col].isNull()).count()/count *100 :.2f}%'\\\n",
    "for col in COVID19_global_spark.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+\n",
      "|    country|Country_code|\n",
      "+-----------+------------+\n",
      "|Afghanistan|          AF|\n",
      "+-----------+------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "global_data_clean = COVID19_global_spark\n",
    "global_data_clean.select(\"country\",\"Country_code\").show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The country code is 2 digit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 Explore and Cleaning *COVID19_usefulFeatures_spark*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Country_Region': '0.00%',\n",
       " 'Population_Size': '0.00%',\n",
       " 'Tourism': '0.00%',\n",
       " 'Date_FirstFatality': '15.22%',\n",
       " 'Date_FirstConfirmedCase': '0.00%',\n",
       " 'Latitude': '0.00%',\n",
       " 'Longtitude': '0.00%',\n",
       " 'Mean_Age': '0.00%',\n",
       " 'Lockdown_Date': '17.93%',\n",
       " 'Lockdown_Type': '17.93%',\n",
       " 'Country_Code': '0.00%'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the Null value columns\n",
    "count = COVID19_usefulFeatures_spark.count()\n",
    "{col: f'{ COVID19_usefulFeatures_spark.filter(COVID19_usefulFeatures_spark[col].isNull()).count()/count *100 :.2f}%'\\\n",
    "for col in COVID19_usefulFeatures_spark.columns}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NULL values are meaningful,Just Keeping \n",
    "- Date_FirstFatality: Date of the first Fatality of the COVID-19\n",
    "- Lockdown_Date: date of the lockdown\n",
    "- Lockdown_Type: type of the lockdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "usefulFeatures_cleaned = COVID19_usefulFeatures_spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 Explore and Cleaning *WORLD DATA by country (2020)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Country': '0.00%', 'GDP per capita': '0.00%', 'ISO-code': '0.00%'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = country_GDP_spark.count()\n",
    "{col: f'{ country_GDP_spark.filter(country_GDP_spark[col].isNull()).count()/count *100 :.2f}%'\\\n",
    "for col in country_GDP_spark.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_GDP_cleaned = country_GDP_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Country': '0.00%', 'Life expectancy': '0.00%', 'ISO-code': '0.00%'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = country_life_expectancy_spark.count()\n",
    "{col: f'{ country_life_expectancy_spark.filter(country_life_expectancy_spark[col].isNull()).count()/count *100 :.2f}%'\\\n",
    "for col in country_life_expectancy_spark.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_life_expectancy_cleaned = country_life_expectancy_spark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Country': '0.00%', 'Median age': '0.00%', 'ISO-code': '0.45%'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = country_median_age_spark.count()\n",
    "{col: f'{ country_median_age_spark.filter(country_median_age_spark[col].isNull()).count()/count *100 :.2f}%'\\\n",
    "for col in country_median_age_spark.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-----+\n",
      "|country               |count|\n",
      "+----------------------+-----+\n",
      "|British Virgin Islands|1    |\n",
      "+----------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dict_null = country_median_age_spark.select(\"Country\",\"ISO-code\")\\\n",
    "                          .filter(country_median_age_spark[\"ISO-code\"].isNull()).groupBy(\"country\").count()\n",
    "dict_null.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_median_age_cleaned = country_median_age_spark.fillna({\"ISO-code\":\"VGB\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Country': '0.00%', 'Population growth': '0.00%', 'ISO-code': '0.00%'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = country_population_growth_spark.count()\n",
    "{col: f'{ country_population_growth_spark.filter(country_population_growth_spark[col].isNull()).count()/count *100 :.2f}%'\\\n",
    "for col in country_population_growth_spark.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_population_growth_cleaned = country_population_growth_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Country': '0.00%', 'Urbanization rate': '0.00%', 'ISO-code': '0.00%'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = country_urbanization_rate_spark.count()\n",
    "{col: f'{ country_urbanization_rate_spark.filter(country_urbanization_rate_spark[col].isNull()).count()/count *100 :.2f}%'\\\n",
    "for col in country_urbanization_rate_spark.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_urbanization_rate_cleaned = country_urbanization_rate_spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "The dimension table is the entry point for data, There are four tables *country_region_dim*  *time_dim*  *vaccines_dim*   *source_dim*  and each measurement event in the world has a one-to-one relationship with the corresponding fact table row. There is one fact table *vaccinations_fact*.\n",
    "\n",
    "![DataModel.jpg](image/DataModel.jpg)\n",
    "\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DataModel.jpg](image/ETL.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1816\r\n",
      "-rw-r--r--   1 tom  staff    1060  3  2 07:58 LICENSE\r\n",
      "-rw-r--r--   1 tom  staff      23  3  2 07:58 README.md\r\n",
      "drwxr-xr-x@  7 tom  staff     224  3  2 07:58 \u001b[34mdata\u001b[m\u001b[m\r\n",
      "-rw-r--r--@  1 tom  staff  895638  3  3 19:57 data.zip\r\n",
      "drwxr-xr-x  15 tom  staff     480  3  3 20:50 \u001b[34mdocker-airflow\u001b[m\u001b[m\r\n",
      "drwxr-xr-x   6 tom  staff     192  3  3 18:08 \u001b[34mimage\u001b[m\u001b[m\r\n",
      "-rw-r--r--   1 tom  staff   24026  3  3 21:30 research.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "! ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "- LICENSE\n",
    "- README.md\n",
    "- data   # raw data files\n",
    "- image # project relevant images\n",
    "- docker-airflow #  DAG files \n",
    "- research.ipynb # The project jupyter notebook file\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1 Install Airflow Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Download docker and installing\n",
    "https://www.docker.com/products/docker-desktop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Pull docker-airflow\n",
    "```\n",
    "docker pull puckel/docker-airflow\n",
    "\n",
    "cd <project path>/docker-airflow/\n",
    "\n",
    "docker build --rm --build-arg AIRFLOW_DEPS=\"datadog,dask\" -t puckel/docker-airflow .\n",
    "\n",
    "docker build --rm --build-arg PYTHON_DEPS=\"flask_oauthlib>=0.9\" -t puckel/docker-airflow .\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3. Run Airflow Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "docker-compose -f docker-compose-LocalExecutor.yml up -d -v $(pwd)/requirements.txt:/requirements.txt\n",
    "\n",
    "or \n",
    "\n",
    "docker run -d -p 8080:8080 puckel/docker-airflow webserver -v $(pwd)/plugins/:/usr/local/airflow/plugins -v $(pwd)/requirements.txt:/requirements.txt\n",
    "\n",
    "docker ps\n",
    "\n",
    "docker exec -it <container_id> /bin/bash\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://localhost:8080/admin/\n",
    "\n",
    "<img src=\"image/localhost.png\" width=\"400\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform quality checks here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
