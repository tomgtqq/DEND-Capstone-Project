{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "### WHO-COVID-19-Data-Warehouse-Redshift\n",
    "\n",
    "#### Project Summary\n",
    "The main goal of the project to create a Data Lake in S3 using Airflow trigger Spark.  \n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import configparser\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as func\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"WHO-COVID-19-Data-Warehouse-Redshift\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "The scope of project is to build a Data Mode to analysis CVID-19 world vaccination progress. For example We can analysis where need to speed up vaccination progress.\n",
    "\n",
    "#### The following technologies were used: \n",
    "- Spark\n",
    "- Airflow\n",
    "- AWS Redshift, S3\n",
    "\n",
    "#### Describe and Gather Data \n",
    "\n",
    "##### 1.The Data sources:\n",
    "\n",
    "The Daily and Total Vaccination for COVID-19 in the world is provided by Kaggle\n",
    "- [country_vaccinations.csv](https://www.kaggle.com/gpreda/covid-world-vaccination-progress)\n",
    "\n",
    "WHO Coronavirus Disease (COVID-19) is provided by WHO\n",
    "- [WHO-COVID-19-global-data.csv](https://covid19.who.int/)\n",
    "There are 1002510 rows\n",
    "\n",
    "ISO country code provide by Kaggle\n",
    "- [country_code.csv](https://www.kaggle.com/koki25ando/country-code)\n",
    "\n",
    "The Data contains 12 columns provide by Kaggle\n",
    " - [ Countries_usefulFeatures.csv](https://www.kaggle.com/ishivinal/covid19-useful-features-by-country)\n",
    " \n",
    "The Data extracted from Wikipedia's list of countries by category is provided by Kaggle \n",
    " - [WORLD DATA by country (2020)](https://www.kaggle.com/daniboy370/world-data-by-country-2020?select=Life+expectancy.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.Gather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set('spark.sql.session.timeZone', 'UTC') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVID19_vaccinations_spark = spark.read.csv(\"data/country_vaccinations.csv\",sep=\",\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The data contains the following information:\n",
    "\n",
    " - Country- this is the country for which the vaccination information is provided;\n",
    " - Country ISO Code - ISO code for the country;\n",
    " - Date - date for the data entry; for some of the dates we have only the daily vaccinations, for others, only the (cumulative) total;\n",
    " - Total number of vaccinations - this is the absolute number of total immunizations in the country;\n",
    " - Total number of people vaccinated - a person, depending on the immunization scheme, will receive one or more (typically 2) vaccines; at a certain moment, the number of vaccination might be larger than the number of people;\n",
    " - Total number of people fully vaccinated - this is the number of people that received the entire set of immunization according to the immunization scheme (typically 2); at a certain moment in time, there might be a certain number of people that received one vaccine and another number (smaller) of people that received all vaccines in the scheme;\n",
    " - Daily vaccinations (raw) - for a certain data entry, the number of vaccination for that date/country;\n",
    " - Daily vaccinations - for a certain data entry, the number of vaccination for that date/country;\n",
    " - Total vaccinations per hundred - ratio (in percent) between vaccination number and total population up to the date in the country;\n",
    " - Total number of people vaccinated per hundred - ratio (in percent) between population immunized and total population up to the date in the country;\n",
    " - Total number of people fully vaccinated per hundred - ratio (in percent) between population fully immunized and total population up to the date in the country;\n",
    " - Number of vaccinations per day - number of daily vaccination for that day and country;\n",
    " - Daily vaccinations per million - ratio (in ppm) between vaccination number and total population for the current date in the country;\n",
    " - Vaccines used in the country - total number of vaccines used in the country (up to date);\n",
    " - Source name - source of the information (national authority, international organization, local organization etc.);\n",
    " - Source website - website of the source of information;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country: string (nullable = true)\n",
      " |-- iso_code: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- total_vaccinations: double (nullable = true)\n",
      " |-- people_vaccinated: double (nullable = true)\n",
      " |-- people_fully_vaccinated: double (nullable = true)\n",
      " |-- daily_vaccinations_raw: double (nullable = true)\n",
      " |-- daily_vaccinations: double (nullable = true)\n",
      " |-- total_vaccinations_per_hundred: double (nullable = true)\n",
      " |-- people_vaccinated_per_hundred: double (nullable = true)\n",
      " |-- people_fully_vaccinated_per_hundred: double (nullable = true)\n",
      " |-- daily_vaccinations_per_million: double (nullable = true)\n",
      " |-- vaccines: string (nullable = true)\n",
      " |-- source_name: string (nullable = true)\n",
      " |-- _c14: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "COVID19_vaccinations_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-------------------+------------------+-----------------+-----------------------+----------------------+------------------+------------------------------+-----------------------------+-----------------------------------+------------------------------+---------------+------------------+----+\n",
      "|country|iso_code|               date|total_vaccinations|people_vaccinated|people_fully_vaccinated|daily_vaccinations_raw|daily_vaccinations|total_vaccinations_per_hundred|people_vaccinated_per_hundred|people_fully_vaccinated_per_hundred|daily_vaccinations_per_million|       vaccines|       source_name|_c14|\n",
      "+-------+--------+-------------------+------------------+-----------------+-----------------------+----------------------+------------------+------------------------------+-----------------------------+-----------------------------------+------------------------------+---------------+------------------+----+\n",
      "|Albania|     ALB|2021-01-09 16:00:00|               0.0|              0.0|                   null|                  null|              null|                           0.0|                          0.0|                               null|                          null|Pfizer/BioNTech|Ministry of Health|null|\n",
      "+-------+--------+-------------------+------------------+-----------------+-----------------------+----------------------+------------------+------------------------------+-----------------------------+-----------------------------------+------------------------------+---------------+------------------+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "COVID19_vaccinations_spark.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVID19_global_spark = spark.read.csv(\"data/WHO-COVID-19-global-data.csv\",sep=\",\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date_reported: string (nullable = true)\n",
      " |-- Country_code: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- WHO_region: string (nullable = true)\n",
      " |-- New_cases: integer (nullable = true)\n",
      " |-- Cumulative_cases: integer (nullable = true)\n",
      " |-- New_deaths: integer (nullable = true)\n",
      " |-- Cumulative_deaths: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "COVID19_global_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1002510 rows\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {COVID19_global_spark.count()} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+-----------+----------+---------+----------------+----------+-----------------+\n",
      "|Date_reported|Country_code|    Country|WHO_region|New_cases|Cumulative_cases|New_deaths|Cumulative_deaths|\n",
      "+-------------+------------+-----------+----------+---------+----------------+----------+-----------------+\n",
      "|     2020/1/3|          AF|Afghanistan|      EMRO|        0|               0|         0|                0|\n",
      "|     2020/1/4|          AF|Afghanistan|      EMRO|        0|               0|         0|                0|\n",
      "|     2020/1/5|          AF|Afghanistan|      EMRO|        0|               0|         0|                0|\n",
      "|     2020/1/6|          AF|Afghanistan|      EMRO|        0|               0|         0|                0|\n",
      "|     2020/1/7|          AF|Afghanistan|      EMRO|        0|               0|         0|                0|\n",
      "+-------------+------------+-----------+----------+---------+----------------+----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "COVID19_global_spark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_code_spark = spark.read.csv(\"data/country_code.csv\",sep=\",\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country_name: string (nullable = true)\n",
      " |-- code_2digit: string (nullable = true)\n",
      " |-- code_3digit: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country_code_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+-----------+\n",
      "|  Country_name|code_2digit|code_3digit|\n",
      "+--------------+-----------+-----------+\n",
      "|   Afghanistan|         AF|        AFG|\n",
      "| Aland Islands|         AX|        ALA|\n",
      "|       Albania|         AL|        ALB|\n",
      "|       Algeria|         DZ|        DZA|\n",
      "|American Samoa|         AS|        ASM|\n",
      "+--------------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country_code_spark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVID19_usefulFeatures_spark = spark.read.csv(\"data/Countries_usefulFeatures.csv\",sep=\",\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Country_Region: Name of the country\n",
    "- Population_Size: the population size 2018 stats\n",
    "- Tourism: International tourism, number of arrivals 2018\n",
    "- Date_FirstFatality: Date of the first Fatality of the COVID-19\n",
    "- Date_FirstConfirmedCase: Date of the first confirmed case of the COVID-19\n",
    "- Latitude\n",
    "- Longitude\n",
    "- Mean_Age: mean age of the population 2018 stats\n",
    "- Lockdown_Date: date of the lockdown\n",
    "- Lockdown_Type: type of the lockdown\n",
    "- Country_Code: 3 digit country code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country_Region: string (nullable = true)\n",
      " |-- Population_Size: integer (nullable = true)\n",
      " |-- Tourism: integer (nullable = true)\n",
      " |-- Date_FirstFatality: timestamp (nullable = true)\n",
      " |-- Date_FirstConfirmedCase: timestamp (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longtitude: double (nullable = true)\n",
      " |-- Mean_Age: double (nullable = true)\n",
      " |-- Lockdown_Date: timestamp (nullable = true)\n",
      " |-- Lockdown_Type: string (nullable = true)\n",
      " |-- Country_Code: string (nullable = true)\n",
      "\n",
      "+--------------+---------------+-------+-------------------+-----------------------+----------+------------------+--------+-------------------+-------------+------------+\n",
      "|Country_Region|Population_Size|Tourism| Date_FirstFatality|Date_FirstConfirmedCase|  Latitude|        Longtitude|Mean_Age|      Lockdown_Date|Lockdown_Type|Country_Code|\n",
      "+--------------+---------------+-------+-------------------+-----------------------+----------+------------------+--------+-------------------+-------------+------------+\n",
      "|   Afghanistan|       37172386|  14000|2020-03-22 16:00:00|    2020-02-24 16:00:00|  33.93911|         67.709953|    17.3|2020-03-23 16:00:00|         Full|         AFG|\n",
      "|       Albania|        2866376|5340000|2020-03-11 16:00:00|    2020-03-09 16:00:00| 41.153332|         20.168331|    36.2|2020-03-07 16:00:00|         Full|         ALB|\n",
      "|       Algeria|       42228429|2657000|2020-03-12 16:00:00|    2020-02-25 16:00:00| 28.033886|1.6596259999999998|    27.5|2020-03-23 16:00:00|         Full|         DZA|\n",
      "|       Andorra|          77006|3042000|2020-03-22 16:00:00|    2020-03-02 16:00:00| 42.546245|          1.601554|    37.0|2020-03-15 16:00:00|         Full|         AND|\n",
      "|        Angola|       30809762| 218000|2020-03-29 16:00:00|    2020-03-20 16:00:00|-11.202692|         17.873887|    16.4|               null|         null|         AGO|\n",
      "+--------------+---------------+-------+-------------------+-----------------------+----------+------------------+--------+-------------------+-------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "COVID19_usefulFeatures_spark.printSchema()\n",
    "COVID19_usefulFeatures_spark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_GDP_spark = spark.read.csv(\"data/WORLD-DATA-by-country-2020/GDP_per_capita.csv\",sep=\",\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country: string (nullable = true)\n",
      " |-- GDP per capita: double (nullable = true)\n",
      " |-- ISO-code: string (nullable = true)\n",
      "\n",
      "+-------------------+--------------+--------+\n",
      "|            Country|GDP per capita|ISO-code|\n",
      "+-------------------+--------------+--------+\n",
      "|             Angola|        2182.0|     AFG|\n",
      "|Antigua and Barbuda|       14866.0|     ALB|\n",
      "|          Argentina|       16091.0|     DZA|\n",
      "|             Angola|        6763.0|     AGO|\n",
      "|Antigua and Barbuda|       30593.0|     ATG|\n",
      "+-------------------+--------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country_GDP_spark.printSchema()\n",
    "country_GDP_spark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_life_expectancy_spark = spark.read.csv(\"data/WORLD-DATA-by-country-2020/Life_expectancy.csv\",sep=\",\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country: string (nullable = true)\n",
      " |-- life_expectancy: double (nullable = true)\n",
      " |-- iso_code: string (nullable = true)\n",
      "\n",
      "+-------------------+---------------+--------+\n",
      "|            country|life_expectancy|iso_code|\n",
      "+-------------------+---------------+--------+\n",
      "|        Afghanistan|           64.5|     AFG|\n",
      "|            Algeria|           76.7|     DZA|\n",
      "|            Andorra|           81.8|     AND|\n",
      "|             Angola|           60.8|     AGO|\n",
      "|Antigua and Barbuda|           76.9|     ATG|\n",
      "+-------------------+---------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country_life_expectancy_spark.printSchema()\n",
    "country_life_expectancy_spark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country: string (nullable = true)\n",
      " |-- median_age: double (nullable = true)\n",
      " |-- iso_code: string (nullable = true)\n",
      "\n",
      "+--------------+----------+--------+\n",
      "|       country|median_age|iso_code|\n",
      "+--------------+----------+--------+\n",
      "|   Afghanistan|      27.4|     AFG|\n",
      "|       Albania|      32.9|     ALB|\n",
      "|       Algeria|      28.1|     DZA|\n",
      "|American Samoa|      25.5|     ASM|\n",
      "|       Andorra|      44.3|     AND|\n",
      "+--------------+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country_median_age_spark = spark.read.csv(\"data/WORLD-DATA-by-country-2020/Median_age.csv\",sep=\",\", inferSchema=True, header=True)\n",
    "country_median_age_spark.printSchema()\n",
    "country_median_age_spark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country: string (nullable = true)\n",
      " |-- population_growth: double (nullable = true)\n",
      " |-- iso_code: string (nullable = true)\n",
      "\n",
      "+--------------+-----------------+--------+\n",
      "|       country|population_growth|iso_code|\n",
      "+--------------+-----------------+--------+\n",
      "|   Afghanistan|             2.41|     AFG|\n",
      "|       Albania|             0.26|     ALB|\n",
      "|       Algeria|             1.89|     DZA|\n",
      "|American Samoa|            -0.26|     ASM|\n",
      "|       Andorra|             0.63|     AND|\n",
      "+--------------+-----------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country_population_growth_spark = spark.read.csv(\"data/WORLD-DATA-by-country-2020/Population_growth.csv\",sep=\",\", inferSchema=True, header=True)\n",
    "country_population_growth_spark.printSchema()\n",
    "country_population_growth_spark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country: string (nullable = true)\n",
      " |-- urbanization_rate: double (nullable = true)\n",
      " |-- iso_code: string (nullable = true)\n",
      "\n",
      "+---------+-----------------+--------+\n",
      "|  country|urbanization_rate|iso_code|\n",
      "+---------+-----------------+--------+\n",
      "|   Monaco|            100.0|     MCO|\n",
      "|    Nauru|            100.0|     NRU|\n",
      "|Singapore|            100.0|     SGP|\n",
      "| Anguilla|            100.0|     AIA|\n",
      "|  Bermuda|            100.0|     BMU|\n",
      "+---------+-----------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country_urbanization_rate_spark = spark.read.csv(\"data/WORLD-DATA-by-country-2020/Urbanization_rate.csv\",sep=\",\", inferSchema=True, header=True)\n",
    "country_urbanization_rate_spark.printSchema()\n",
    "country_urbanization_rate_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Explore and Cleaning  *COVID19_vaccinations_spark DataFrame*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': '0.00%',\n",
       " 'iso_code': '6.85%',\n",
       " 'date': '0.00%',\n",
       " 'total_vaccinations': '34.25%',\n",
       " 'people_vaccinated': '44.01%',\n",
       " 'people_fully_vaccinated': '62.53%',\n",
       " 'daily_vaccinations_raw': '44.37%',\n",
       " 'daily_vaccinations': '3.47%',\n",
       " 'total_vaccinations_per_hundred': '34.25%',\n",
       " 'people_vaccinated_per_hundred': '44.01%',\n",
       " 'people_fully_vaccinated_per_hundred': '62.53%',\n",
       " 'daily_vaccinations_per_million': '3.47%',\n",
       " 'vaccines': '0.00%',\n",
       " 'source_name': '0.00%',\n",
       " '_c14': '100.00%'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the Null value columns\n",
    "count = COVID19_vaccinations_spark.count()\n",
    "{col: f'{ COVID19_vaccinations_spark.filter(COVID19_vaccinations_spark[col].isNull()).count()/count *100 :.2f}%'\\\n",
    "for col in COVID19_vaccinations_spark.columns}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'iso_code' fill NULL as iso country code. Other column null value are filled with 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|         country|count|\n",
      "+----------------+-----+\n",
      "|           Wales|   76|\n",
      "|         England|   76|\n",
      "|        Scotland|   76|\n",
      "|Northern Ireland|   76|\n",
      "+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dict_null = COVID19_vaccinations_spark.select(\"country\",\"iso_code\")\\\n",
    "                          .filter(COVID19_vaccinations_spark[\"iso_code\"].isNull()).groupBy(\"country\").count()\n",
    "dict_null.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaccinations_cleaned = COVID19_vaccinations_spark.fillna({\"iso_code\":\"GBR\", \"total_vaccinations\":0.0, \"people_vaccinated\":0.0, \"people_fully_vaccinated\":0.0,\\\n",
    "                       \"daily_vaccinations_raw\":0.0, \"daily_vaccinations\":0.0, \"total_vaccinations_per_hundred\":0.0,\\\n",
    "                                    \"people_vaccinated_per_hundred\":0.0, \"people_fully_vaccinated_per_hundred\":0.0,\\\n",
    "                                    \"daily_vaccinations_per_million\":0.0\n",
    "                                   })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Explore and Cleaning *COVID19_global_spark* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date_reported': '0.00%',\n",
       " 'Country_code': '0.00%',\n",
       " 'Country': '0.00%',\n",
       " 'WHO_region': '0.00%',\n",
       " 'New_cases': '0.00%',\n",
       " 'Cumulative_cases': '0.00%',\n",
       " 'New_deaths': '0.00%',\n",
       " 'Cumulative_deaths': '0.00%'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the Null value columns\n",
    "count = COVID19_global_spark.count()\n",
    "{col: f'{ COVID19_global_spark.filter(COVID19_global_spark[col].isNull()).count()/count *100 :.2f}%'\\\n",
    "for col in COVID19_global_spark.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+\n",
      "|    country|Country_code|\n",
      "+-----------+------------+\n",
      "|Afghanistan|          AF|\n",
      "+-----------+------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "global_data_clean = COVID19_global_spark\n",
    "global_data_clean.select(\"country\",\"Country_code\").show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The country code is 2 digit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 Explore and Cleaning *COVID19_usefulFeatures_spark*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Country_Region': '0.00%',\n",
       " 'Population_Size': '0.00%',\n",
       " 'Tourism': '0.00%',\n",
       " 'Date_FirstFatality': '15.22%',\n",
       " 'Date_FirstConfirmedCase': '0.00%',\n",
       " 'Latitude': '0.00%',\n",
       " 'Longtitude': '0.00%',\n",
       " 'Mean_Age': '0.00%',\n",
       " 'Lockdown_Date': '17.93%',\n",
       " 'Lockdown_Type': '17.93%',\n",
       " 'Country_Code': '0.00%'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the Null value columns\n",
    "count = COVID19_usefulFeatures_spark.count()\n",
    "{col: f'{ COVID19_usefulFeatures_spark.filter(COVID19_usefulFeatures_spark[col].isNull()).count()/count *100 :.2f}%'\\\n",
    "for col in COVID19_usefulFeatures_spark.columns}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NULL values are meaningful,Just Keeping \n",
    "- Date_FirstFatality: Date of the first Fatality of the COVID-19\n",
    "- Lockdown_Date: date of the lockdown\n",
    "- Lockdown_Type: type of the lockdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "usefulFeatures_cleaned = COVID19_usefulFeatures_spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 Explore and Cleaning *WORLD DATA by country (2020)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Country': '0.00%', 'GDP per capita': '0.00%', 'ISO-code': '0.00%'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = country_GDP_spark.count()\n",
    "{col: f'{ country_GDP_spark.filter(country_GDP_spark[col].isNull()).count()/count *100 :.2f}%'\\\n",
    "for col in country_GDP_spark.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_GDP_cleaned = country_GDP_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': '0.00%', 'life_expectancy': '0.00%', 'iso_code': '0.00%'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = country_life_expectancy_spark.count()\n",
    "{col: f'{ country_life_expectancy_spark.filter(country_life_expectancy_spark[col].isNull()).count()/count *100 :.2f}%'\\\n",
    "for col in country_life_expectancy_spark.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_life_expectancy_cleaned = country_life_expectancy_spark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': '0.00%', 'median_age': '0.00%', 'iso_code': '0.45%'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = country_median_age_spark.count()\n",
    "{col: f'{ country_median_age_spark.filter(country_median_age_spark[col].isNull()).count()/count *100 :.2f}%'\\\n",
    "for col in country_median_age_spark.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-----+\n",
      "|country               |count|\n",
      "+----------------------+-----+\n",
      "|British Virgin Islands|1    |\n",
      "+----------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dict_null = country_median_age_spark.select(\"Country\",\"iso_code\")\\\n",
    "                          .filter(country_median_age_spark[\"iso_code\"].isNull()).groupBy(\"country\").count()\n",
    "dict_null.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_median_age_cleaned = country_median_age_spark.fillna({\"iso_code\":\"VGB\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': '0.00%', 'population_growth': '0.00%', 'iso_code': '0.00%'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = country_population_growth_spark.count()\n",
    "{col: f'{ country_population_growth_spark.filter(country_population_growth_spark[col].isNull()).count()/count *100 :.2f}%'\\\n",
    "for col in country_population_growth_spark.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_population_growth_cleaned = country_population_growth_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': '0.00%', 'urbanization_rate': '0.00%', 'iso_code': '0.00%'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = country_urbanization_rate_spark.count()\n",
    "{col: f'{ country_urbanization_rate_spark.filter(country_urbanization_rate_spark[col].isNull()).count()/count *100 :.2f}%'\\\n",
    "for col in country_urbanization_rate_spark.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_urbanization_rate_cleaned = country_urbanization_rate_spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "The dimension table is the entry point for data, There are four tables *country_region_dim*  *time_dim*  *vaccines_dim*   *source_dim*  and each measurement event in the world has a one-to-one relationship with the corresponding fact table row. There is one fact table *vaccinations_fact*.\n",
    "\n",
    "![DataModel.jpg](image/DataModel.jpg)\n",
    "\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DataModel.jpg](image/ETL.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "- LICENSE\n",
    "- README.md\n",
    "- data   # raw data files\n",
    "- image # project relevant images\n",
    "- docker-airflow #  DAG files \n",
    "- research.ipynb # The project jupyter notebook file\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Install Airflow Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Download docker and installing\n",
    "https://www.docker.com/products/docker-desktop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Installation docker-airflow \n",
    "```\n",
    "docker pull puckel/docker-airflow\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Build docker-airflow\n",
    "```\n",
    "cd <project path>/docker-airflow/\n",
    "\n",
    "docker build --rm --build-arg AIRFLOW_DEPS=\"datadog,dask\" -t puckel/docker-airflow .\n",
    "\n",
    "docker build --rm --build-arg PYTHON_DEPS=\"flask_oauthlib>=0.9\" -t puckel/docker-airflow .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3. Run Airflow Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "docker-compose -f docker-compose-LocalExecutor.yml up -d\n",
    "\n",
    "docker ps\n",
    "\n",
    "docker exec -it <container_id> /bin/bash\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://localhost:8080/admin/\n",
    "\n",
    "<img src=\"image/localhost.jpg\" width=\"400\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Config Airflow Connections¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.Config aws_credentials   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/aws_credentials.jpg\" width=\"400\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Login AWS User access ID \n",
    "- Password AWS User secret key ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.Config redshift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/redshift.jpg\" width=\"400\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.Config variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/variables1.jpg\" width=\"400\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/variables2.jpg\" width=\"400\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The project using airflow to create an ETL pipeline, COPAY data from S3 to Redshift as staging tables, and transform data into Fact and dim tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/dag.jpg\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aginity is a very effective debug tool to check etl_loader_errors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/debug.jpg\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    " Create a customer operator 'DataQualityOperator' to check date quality, When the staging table were copied , the fact and dim tables were loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "\n",
    "- **vaccinations_fact**\n",
    "\n",
    "| Column Feature | Data type | Description |\n",
    "| ----------- | ----------- |----------- |\n",
    "| id | INTEGER | Record ID\n",
    "| date | DATE |  date for the data entry\n",
    "| vaccines_id | INTEGER | The id of vaccines, reference *vaccines_dim* table\n",
    "| source_id | INTEGER | The id of source, reference *source_dim* table\n",
    "| new_cases | INTEGER | Report new case\n",
    "| cumulative_deaths | INTEGER | The cumulative deaths of the country\n",
    "| total_vaccinations | INTEGER | this is the absolute number of total immunizations in the country\n",
    "| people_vaccinated | INTEGER | a person, depending on the immunization scheme, will receive one or more (typically 2) vaccines; at a certain moment, the number of vaccination might be larger than the number of people\n",
    "| people_fully_vaccinated | INTEGER | this is the number of people that received the entire set of immunization according to the immunization scheme (typically 2); at a certain moment in time, there might be a certain number of people that received one vaccine and another number (smaller) of people that received all vaccines in the scheme\n",
    "| daily_vaccinations_raw | INTEGER |  for a certain data entry, the number of vaccination for that date/country\n",
    "| daily_vaccinations | INTEGER |   for a certain data entry, the number of vaccination for that date/country\n",
    "| total_vaccinations_per_hundred | FLOAT | ratio (in percent) between vaccination number and total population up to the date in the country\n",
    "| people_vaccinated_per_hundred | FLOAT |  ratio (in percent) between population immunized and total population up to the date in the country\n",
    "| people_vaccinated_per_hundred | FLOAT |  ratio (in percent) between population fully immunized and total population up to the date in the country\n",
    "| daily_vaccinations_per_million | FLOAT |  ratio (in ppm) between vaccination number and total population for the current date in the country\n",
    "\n",
    "- **country_region_dim**\n",
    "\n",
    "| Column Feature | Data type | Description |\n",
    "| ----------- | ----------- |----------- |\n",
    "| iso_code | VARCHAR |  ISO country code\n",
    "| population | BIGINT |  the population size 2018 stats\n",
    "| mean_age | BIGINT |  mean age of the population 2018 stats\n",
    "| first_fatality | DATE |  Date of the first Fatality of the COVID-19\n",
    "| first_confirmed_case | DATE |  Date of the first confirmed case of the COVID-19\n",
    "| lockdown_Date | DATE | date of the lockdown\n",
    "| lockdown_Type | VARCHAR | type of the lockdown\n",
    "| latitude | DATE | latitude value for BI\n",
    "| longtitude | FLOAT | longtitude value for Data visualization\n",
    "| GDP | FLOAT | GDP per capita\n",
    "| life_expectancy | FLOAT | List of countries by life expectancy from wiki\n",
    "| population_growth| FLOAT | List of countries by population growth from wiki\n",
    "| urbanization_rate| FLOAT | Urbanization by country from wiki\n",
    "\n",
    "- **time_dim**\n",
    "\n",
    "| Column Feature | Data type | Description |\n",
    "| ----------- | ----------- |----------- |\n",
    "| date | DATE |  date for the data entry\n",
    "| year | INTEGER |  using aggregation by year\n",
    "| month | INTEGER |  using aggregation by month\n",
    "| week_of_year | INTEGER |  using aggregation by week\n",
    "\n",
    "- **vaccines_dim**\n",
    "\n",
    "| Column Feature | Data type | Description |\n",
    "| ----------- | ----------- |----------- |\n",
    "| vaccines_id | INTEGER |  The id of vaccines\n",
    "| name | VARCHAR |  The vaccines name\n",
    "\n",
    "\n",
    "- **source_dim**\n",
    "\n",
    "| Column Feature | Data type | Description |\n",
    "| ----------- | ----------- |----------- |\n",
    "| source_id | INTEGER |  The id of source where info comes from\n",
    "| name | VARCHAR |  The source name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "  \n",
    "  - Spark to explore the dataset, In this case, I didn't build a data lake, Because Redshift is more suitable for this type of data.\n",
    "  - I used Redshift to build a Data warehouse\n",
    "  - I used Airflow to build an ETL pipeline that extracted data from s3 to Redshift.\n",
    "\n",
    "* Propose how often the data should be updated and why.\n",
    "\n",
    "  - The data should be updated daily at the same time as WHO records.\n",
    "\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    "   - Using Spark to process such large amounts of data is faster and store into s3, then design Redshift read data from s3 as a staging table\n",
    " \n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "   - Using Airflow to create a dag for tableau query data from the data warehouse.\n",
    " \n",
    " * The database needed to be accessed by 100+ people.\n",
    "   - Provide AWS Redshift role ARN and Datebase username&password to people who using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas-redshift in c:\\users\\tomge\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.0.4)\n",
      "Requirement already satisfied: psycopg2-binary in c:\\users\\tomge\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas-redshift) (2.8.6)\n",
      "Requirement already satisfied: boto3 in c:\\users\\tomge\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas-redshift) (1.17.23)\n",
      "Requirement already satisfied: pandas in c:\\users\\tomge\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas-redshift) (1.2.3)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.23 in c:\\users\\tomge\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from boto3->pandas-redshift) (1.20.23)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in c:\\users\\tomge\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from boto3->pandas-redshift) (0.3.4)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\tomge\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from boto3->pandas-redshift) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\tomge\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->pandas-redshift) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\tomge\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->pandas-redshift) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\tomge\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->pandas-redshift) (1.20.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\tomge\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from botocore<1.21.0,>=1.20.23->boto3->pandas-redshift) (1.26.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tomge\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->pandas-redshift) (1.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\tomge\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas-redshift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data from Redshift Warehouse API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_redshift as pd_r\n",
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dwh.cfg'))\n",
    "\n",
    "pd_r.connect_to_redshift(\n",
    "    dbname = config.get('CLUSTER', 'DB_NAME'),\n",
    "    host = config.get('CLUSTER', 'HOST'),\n",
    "    port = config.get('CLUSTER', 'DB_PORT'),\n",
    "    user = config.get('CLUSTER', 'DB_USER'),\n",
    "    password = config.get('CLUSTER', 'DB_PASSWORD')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>iso_code</th>\n",
       "      <th>date</th>\n",
       "      <th>vaccines_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>new_cases</th>\n",
       "      <th>cumulative_cases</th>\n",
       "      <th>new_deaths</th>\n",
       "      <th>cumulative_deaths</th>\n",
       "      <th>total_vaccinations</th>\n",
       "      <th>people_vaccinated</th>\n",
       "      <th>people_fully_vaccinated</th>\n",
       "      <th>daily_vaccinations_raw</th>\n",
       "      <th>daily_vaccinations</th>\n",
       "      <th>total_vaccinations_per_hundred</th>\n",
       "      <th>people_vaccinated_per_hundred</th>\n",
       "      <th>people_fully_vaccinated_per_hundred</th>\n",
       "      <th>daily_vaccinations_per_million</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AFG</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1677782</td>\n",
       "      <td>UGA</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>20641</td>\n",
       "      <td>DZA</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3748.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1678212</td>\n",
       "      <td>UKR</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3051.0</td>\n",
       "      <td>3051.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1713.0</td>\n",
       "      <td>1446.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20643</td>\n",
       "      <td>DZA</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3748.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id iso_code        date  vaccines_id  source_id  new_cases  \\\n",
       "0        0      AFG  2020-01-03          NaN        NaN          0   \n",
       "1  1677782      UGA  2020-01-03          NaN        NaN          0   \n",
       "2    20641      DZA  2020-01-03          2.0        0.0          0   \n",
       "3  1678212      UKR  2020-01-03          4.0        0.0          0   \n",
       "4    20643      DZA  2020-01-03          2.0        0.0          0   \n",
       "\n",
       "   cumulative_cases  new_deaths  cumulative_deaths  total_vaccinations  \\\n",
       "0                 0           0                  0                 NaN   \n",
       "1                 0           0                  0                 NaN   \n",
       "2                 0           0                  0             75000.0   \n",
       "3                 0           0                  0              3051.0   \n",
       "4                 0           0                  0                 NaN   \n",
       "\n",
       "   people_vaccinated  people_fully_vaccinated  daily_vaccinations_raw  \\\n",
       "0                NaN                      NaN                     NaN   \n",
       "1                NaN                      NaN                     NaN   \n",
       "2                NaN                      NaN                     NaN   \n",
       "3             3051.0                      NaN                  1713.0   \n",
       "4                NaN                      NaN                     NaN   \n",
       "\n",
       "   daily_vaccinations  total_vaccinations_per_hundred  \\\n",
       "0                 NaN                             NaN   \n",
       "1                 NaN                             NaN   \n",
       "2              3748.0                            0.17   \n",
       "3              1446.0                            0.01   \n",
       "4              3748.0                             NaN   \n",
       "\n",
       "   people_vaccinated_per_hundred  people_fully_vaccinated_per_hundred  \\\n",
       "0                            NaN                                  NaN   \n",
       "1                            NaN                                  NaN   \n",
       "2                            NaN                                  NaN   \n",
       "3                           0.01                                  NaN   \n",
       "4                            NaN                                  NaN   \n",
       "\n",
       "   daily_vaccinations_per_million  \n",
       "0                             NaN  \n",
       "1                             NaN  \n",
       "2                            85.0  \n",
       "3                            33.0  \n",
       "4                            85.0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vaccinations_fact = pd_r.redshift_to_pandas(\"\"\"\n",
    "    SELECT * FROM vaccinations_fact LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "df_vaccinations_fact.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso_code</th>\n",
       "      <th>population</th>\n",
       "      <th>first_fatality</th>\n",
       "      <th>first_confirmed_case</th>\n",
       "      <th>lockdown_date</th>\n",
       "      <th>lockdown_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longtitude</th>\n",
       "      <th>gdp</th>\n",
       "      <th>life_expectancy</th>\n",
       "      <th>population_growth</th>\n",
       "      <th>urbanization_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>MLT</td>\n",
       "      <td>484630</td>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>Full</td>\n",
       "      <td>35.937496</td>\n",
       "      <td>14.375416</td>\n",
       "      <td>49589</td>\n",
       "      <td>82.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>94.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ARG</td>\n",
       "      <td>44494502</td>\n",
       "      <td>2020-03-09</td>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>Full</td>\n",
       "      <td>-38.416097</td>\n",
       "      <td>-63.616672</td>\n",
       "      <td>19971</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0.88</td>\n",
       "      <td>92.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>JOR</td>\n",
       "      <td>9956011</td>\n",
       "      <td>2020-03-28</td>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>2020-03-21</td>\n",
       "      <td>Full</td>\n",
       "      <td>30.585164</td>\n",
       "      <td>36.238414</td>\n",
       "      <td>9939</td>\n",
       "      <td>74.4</td>\n",
       "      <td>2.19</td>\n",
       "      <td>91.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>DNK</td>\n",
       "      <td>5793636</td>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>Full</td>\n",
       "      <td>56.263920</td>\n",
       "      <td>9.501785</td>\n",
       "      <td>55675</td>\n",
       "      <td>80.8</td>\n",
       "      <td>0.36</td>\n",
       "      <td>88.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>BRA</td>\n",
       "      <td>209469333</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>Partial</td>\n",
       "      <td>-14.235004</td>\n",
       "      <td>-51.925280</td>\n",
       "      <td>17106</td>\n",
       "      <td>75.7</td>\n",
       "      <td>0.87</td>\n",
       "      <td>87.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  iso_code  population first_fatality first_confirmed_case lockdown_date  \\\n",
       "0      MLT      484630     2020-04-09           2020-03-08    2020-03-12   \n",
       "1      ARG    44494502     2020-03-09           2020-03-04    2020-03-20   \n",
       "2      JOR     9956011     2020-03-28           2020-03-04    2020-03-21   \n",
       "3      DNK     5793636     2020-03-15           2020-02-28    2020-03-11   \n",
       "4      BRA   209469333     2020-03-18           2020-02-27    2020-03-17   \n",
       "\n",
       "  lockdown_type   latitude  longtitude    gdp  life_expectancy  \\\n",
       "0          Full  35.937496   14.375416  49589             82.4   \n",
       "1          Full -38.416097  -63.616672  19971             76.5   \n",
       "2          Full  30.585164   36.238414   9939             74.4   \n",
       "3          Full  56.263920    9.501785  55675             80.8   \n",
       "4       Partial -14.235004  -51.925280  17106             75.7   \n",
       "\n",
       "   population_growth  urbanization_rate  \n",
       "0               0.40               94.7  \n",
       "1               0.88               92.1  \n",
       "2               2.19               91.4  \n",
       "3               0.36               88.1  \n",
       "4               0.87               87.1  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_country_region = pd_r.redshift_to_pandas(\"\"\"\n",
    "    SELECT * FROM country_region_dim LIMIT 10\n",
    "\"\"\")\n",
    "df_country_region.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week_of_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2020-02-11</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  year  month  week_of_year\n",
       "0  2020-01-14  2020      1             3\n",
       "1  2020-01-20  2020      1             4\n",
       "2  2020-02-01  2020      2             5\n",
       "3  2020-02-05  2020      2             6\n",
       "4  2020-02-11  2020      2             7"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time = pd_r.redshift_to_pandas(\"\"\"\n",
    "    SELECT * FROM time_dim\n",
    "\"\"\")\n",
    "df_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vaccines_id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Sputnik V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Moderna, Oxford/AstraZeneca, Pfizer/BioNTech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>Pfizer/BioNTech, Sinopharm/Beijing, Sputnik V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>Sinopharm/Beijing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>Pfizer/BioNTech, Sinovac</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vaccines_id                                           name\n",
       "0            2                                      Sputnik V\n",
       "1            6   Moderna, Oxford/AstraZeneca, Pfizer/BioNTech\n",
       "2           10  Pfizer/BioNTech, Sinopharm/Beijing, Sputnik V\n",
       "3           14                              Sinopharm/Beijing\n",
       "4           18                       Pfizer/BioNTech, Sinovac"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vaccines = pd_r.redshift_to_pandas(\"\"\"\n",
    "    SELECT * FROM vaccines_dim\n",
    "\"\"\")\n",
    "df_vaccines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Government of Andorra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Government of Azerbaijan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>Sciensano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>Regional governments via Coronavirus Brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>Cayman Islands Government</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_id                                         name\n",
       "0          2                        Government of Andorra\n",
       "1          6                     Government of Azerbaijan\n",
       "2         10                                    Sciensano\n",
       "3         14  Regional governments via Coronavirus Brasil\n",
       "4         18                    Cayman Islands Government"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_source = pd_r.redshift_to_pandas(\"\"\"\n",
    "    SELECT * FROM source_dim\n",
    "\"\"\")\n",
    "df_source.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I can query data from Redshift DWH and analysis based on the data and look at the vaccination situation in relevant countries and regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
